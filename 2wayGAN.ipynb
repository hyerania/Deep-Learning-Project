{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "from scipy.misc import toimage\n",
    "import skimage.color\n",
    "\n",
    "device = torch.device('cuda')     # Default CUDA device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 512\n",
    "BETA1 = 0.5\n",
    "BETA2 = 0.999\n",
    "LAMBDA = 10\n",
    "ALPHA = 1000\n",
    "numEpochs = 5\n",
    "latentDim = 100\n",
    "trainNum = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        #  Convolutional layers \n",
    "        \n",
    "        # input 512x512x3  output 512x512x16\n",
    "        self.conv1 = nn.Conv2d(3, 16, 5, stride = 1, padding = 1)\n",
    "        self.conv1_bn = nn.BatchNorm2d(16)\n",
    "        \n",
    "        # input 512x512x16  output 256x256x32\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5, stride = 2, padding = 1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(32)\n",
    "        \n",
    "        # input 265x256x32  output 128x128x64\n",
    "        self.conv3 = nn.Conv2d(32, 64, 5, stride = 2, padding = 1)\n",
    "        self.conv3_bn = nn.BatchNorm2d(64)\n",
    "        \n",
    "        # input 128x128x64  output 64x64x128\n",
    "        self.conv4 = nn.Conv2d(64, 128, 5, stride = 2, padding = 1)\n",
    "        self.conv4_bn = nn.BatchNorm2d(128)\n",
    "        \n",
    "        # input 64x64x128  output 32x32x128\n",
    "        # the output of this layer we need layers for global features\n",
    "        self.conv5 = nn.Conv2d(128, 128, 5, stride = 2, padding = 1)\n",
    "        self.conv5_bn = nn.BatchNorm2d(128)\n",
    "        \n",
    "        # convs for global features\n",
    "        # input 32x32x128 output 16x16x128\n",
    "        self.conv51 = nn.Conv2d(128,128,5, stride =2 , padding =1 )\n",
    "        \n",
    "        # input 16x16x128 output 8x8x128\n",
    "        self.conv52 = nn.Conv2d(128,128,5, stride =2 , padding =1 )\n",
    "        \n",
    "        # input 8x8x128 output 1x1x128\n",
    "        self.conv531 = nn.Conv2d(128,128,5, stride =2 , padding =1 )\n",
    "        \n",
    "        # input 1x1x128 output 1x1x128\n",
    "        self.conv532 = nn.Conv2d(128,128,5, stride =2 , padding =1 )\n",
    "        \n",
    "        # input 32x32x128 output 32x32x128\n",
    "        # the global features should be concatenated to the feature map aftere this layer\n",
    "        # the output after concat would be 32x32x256\n",
    "        self.conv6 = nn.Conv2d(128, 128, 5, stride = 1, padding = 1)\n",
    "        \n",
    "        # input 32x32x256 output 32x32x128\n",
    "        self.conv7 = nn.Conv2d(256, 128, 5, stride = 1, padding = 1)\n",
    "        \n",
    "        # deconvolutional layers\n",
    "        # input 32x32x128 output 64x64x128\n",
    "        self.dconv1 = nn.ConvTranspose2d(128, 128, 5, stride = 2, padding = 1)\n",
    "        self.dconv1_bn = nn.BatchNorm2d(128)\n",
    "        \n",
    "        # input 64x64x256 ouput 128x128x128\n",
    "        self.dconv2 = nn.ConvTranspose2d(256, 128, 5, stride = 2, padding = 1)\n",
    "        self.dconv2_bn = nn.BatchNorm2d(128)\n",
    "        \n",
    "        # input 128x128x192 output 256x256x64\n",
    "        self.dconv3 = nn.ConvTranspose2d(192, 64, 5, stride = 2, padding = 1)\n",
    "        self.dconv3_bn = nn.BatchNorm2d(64)\n",
    "        \n",
    "        # input 256x256x96 ouput 512x512x32\n",
    "        self.dconv4 = nn.ConvTranspose2d(96, 32, 5, stride = 2, padding = 1)\n",
    "        self.dconv4_bn = nn.BatchNorm2d(32)\n",
    "        \n",
    "        # final convolutional layers\n",
    "        # input 512x512x48 output 512x512x16\n",
    "        self.conv8 = nn.Conv2d(48, 16, 5, stride = 1, padding = 1)\n",
    "        self.conv8_bn = nn.BatchNorm2d(16)\n",
    "        \n",
    "        # input 512x512x16 output 512x512x3\n",
    "        self.conv9 = nn.Conv2d(16, 3, 5, stride = 1, padding = 1)    \n",
    "        self.conv9_bn = nn.BatchNorm2d(3)\n",
    "        # SELU\n",
    "                \n",
    "    def forward(self, x):\n",
    "        # input 512x512x3 to output 512x512x16\n",
    "        x = self.conv1_bn(F.selu(self.conv1(x)))\n",
    "        \n",
    "        # input 512x512x16 to output 256x256x32\n",
    "        x1 = self.conv2_bn(F.selu(self.conv2(x)))\n",
    "        \n",
    "        # input 256x256x32 to output 128x128x64\n",
    "        x2 = self.conv3_bn(F.selu(self.conv3(x1)))\n",
    "        \n",
    "        # input 128x128x64 to output 64x64x128\n",
    "        x3 = self.conv4_bn(F.selu(self.conv4(x2)))\n",
    "        \n",
    "        # input 64x64x128 to output 32x32x128\n",
    "        x4 = self.conv5_bn(F.selu(self.conv5(x3)))\n",
    "        \n",
    "        #convolutions for global features\n",
    "        # input 32x32x128 to output 16x16x128\n",
    "        x51 = self.conv51(x4)\n",
    "        # input 16x16x128 to output 8x8x128\n",
    "        x52 = self.conv52(x51)\n",
    "        # input 8x8x128 to output 1x1x128\n",
    "        x53 = self.conv532(F.selu(self.conv531(x52)))\n",
    "        x53_temp = torch.cat([x53]*32)\n",
    "        x53_temp = torch.cat([x53_temp]*32,dim=1)\n",
    "        \n",
    "        \n",
    "        # input 32x32x256 to output 32x32x128\n",
    "        x5 = self.conv6(x4)\n",
    "        \n",
    "        # input 32x32x128 to output 32x32x128\n",
    "        x5 = self.conv7(torch.cat(x5,x53_temp))\n",
    "        \n",
    "        # input 32x32x128 to output 64x64x128\n",
    "        xd = self.dconv1(self.dconv1_bn(F.selu(x5)))\n",
    "        \n",
    "        # input 64x64x256 to output 128x128x128\n",
    "        xd = self.dconv2(self.dconv2_bn(F.selu(torch.cat((xd,x3),dim=1))))\n",
    "        \n",
    "        # input 128x128x192 to output 256x256x64\n",
    "        xd = self.dconv3(self.dconv3_bn(F.selu(torch.cat((xd,x2),dim=1))))\n",
    "        \n",
    "        # input 256x256x64 to output 512x512x32\n",
    "        xd = self.dconv4(self.dconv4_bn(F.selu(torch.cat((xd,x1),dim=1))))\n",
    "        \n",
    "        # input 512x512x48 to output 512x512x16\n",
    "        xd = self.conv8(self.conv8_bn(F.selu(torch.cat((xd,x),dim=1))))\n",
    "        \n",
    "        # input 512x512x16 to output 512x512x3\n",
    "        xd = self.conv9(self.conv9_bn(F.selu((xd))))\n",
    "        return xd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        #  Convolutional layers \n",
    "        \n",
    "        # input 512x512x3  output 512x512x16\n",
    "        self.conv1 = nn.Conv2d(3, 16, 5, stride = 1, padding = 1)\n",
    "        self.conv1_in = nn.InstanceNorm2d(16)\n",
    "        \n",
    "        # input 512x512x16  output 256x256x32\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5, stride = 2, padding = 1)\n",
    "        self.conv2_in = nn.InstanceNorm2d(32)\n",
    "        \n",
    "        # input 265x256x32  output 128x128x64\n",
    "        self.conv3 = nn.Conv2d(32, 64, 5, stride = 2, padding = 1)\n",
    "        self.conv3_in = nn.InstanceNorm2d(64)\n",
    "        \n",
    "        # input 128x128x64  output 64x64x128\n",
    "        self.conv4 = nn.Conv2d(64, 128, 5, stride = 2, padding = 1)\n",
    "        self.conv4_in = nn.InstanceNorm2d(128)\n",
    "        \n",
    "        # input 64x64x128  output 32x32x128\n",
    "        # the output of this layer we need layers for global features\n",
    "        self.conv5 = nn.Conv2d(128, 128, 5, stride = 2, padding = 1)\n",
    "        self.conv5_in = nn.InstanceNorm2d(128)\n",
    "        \n",
    "        # input 32x32x128  output 16x16x128\n",
    "        # the output of this layer we need layers for global features\n",
    "        self.conv6 = nn.Conv2d(128, 128, 5, stride = 2, padding = 1)\n",
    "        self.conv6_in = nn.InstanceNorm2d(128)\n",
    "        \n",
    "        # input 16x16x128  output 1x1x1\n",
    "        # the output of this layer we need layers for global features\n",
    "        self.conv6 = nn.Conv2d(128, 1, 5, stride = 32, padding = 1)\n",
    "        self.conv6_in = nn.InstanceNorm2d(1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # input 512x512x3 to output 512x512x16\n",
    "        x = self.conv1_in(F.leaky_relu(self.conv1(x)))\n",
    "        \n",
    "        # input 512x512x16 to output 256x256x32\n",
    "        x = self.conv2_in(F.leaky_relu(self.conv2(x)))\n",
    "        \n",
    "        # input 256x256x32 to output 128x128x64\n",
    "        x = self.conv3_in(F.leaky_relu(self.conv3(x)))\n",
    "        \n",
    "        # input 128x128x64 to output 64x64x128\n",
    "        x = self.conv4_in(F.leaky_relu(self.conv4(x)))\n",
    "        \n",
    "        # input 64x64x128 to output 32x32x128\n",
    "        x = self.conv5_in(F.leaky_relu(self.conv5(x)))\n",
    "        \n",
    "        # input 32x32x128 to output 16x16x128\n",
    "        x = self.conv5_in(F.leaky_relu(self.conv5(x)))\n",
    "        \n",
    "        # input 16x16x128 to output 1x1x1\n",
    "        x = self.conv5_in(F.leaky_relu(self.conv5(x)))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator1 = Generator()\n",
    "# generator2 = Generator()\n",
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz to ./data\\stl10_binary.tar.gz\n"
     ]
    },
    {
     "ename": "EOFError",
     "evalue": "Compressed file ended before the end-of-stream marker was reached",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-b9041b756234>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtrainset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTL10\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'./data'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'unlabeled'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mtrainloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\dellatsni\\adocana\\lib\\site-packages\\torchvision\\datasets\\stl10.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, split, transform, target_transform, download)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_integrity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\dellatsni\\adocana\\lib\\site-packages\\torchvision\\datasets\\cifar.py\u001b[0m in \u001b[0;36mdownload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[0mtar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r:gz\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m         \u001b[0mtar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m         \u001b[0mtar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\dellatsni\\adocana\\lib\\tarfile.py\u001b[0m in \u001b[0;36mextractall\u001b[1;34m(self, path, members, numeric_owner)\u001b[0m\n\u001b[0;32m   2006\u001b[0m             \u001b[1;31m# Do not set_attrs directories, as we will do that further down\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2007\u001b[0m             self.extract(tarinfo, path, set_attrs=not tarinfo.isdir(),\n\u001b[1;32m-> 2008\u001b[1;33m                          numeric_owner=numeric_owner)\n\u001b[0m\u001b[0;32m   2009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2010\u001b[0m         \u001b[1;31m# Reverse sort directories.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\dellatsni\\adocana\\lib\\tarfile.py\u001b[0m in \u001b[0;36mextract\u001b[1;34m(self, member, path, set_attrs, numeric_owner)\u001b[0m\n\u001b[0;32m   2048\u001b[0m             self._extract_member(tarinfo, os.path.join(path, tarinfo.name),\n\u001b[0;32m   2049\u001b[0m                                  \u001b[0mset_attrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mset_attrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2050\u001b[1;33m                                  numeric_owner=numeric_owner)\n\u001b[0m\u001b[0;32m   2051\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2052\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrorlevel\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\dellatsni\\adocana\\lib\\tarfile.py\u001b[0m in \u001b[0;36m_extract_member\u001b[1;34m(self, tarinfo, targetpath, set_attrs, numeric_owner)\u001b[0m\n\u001b[0;32m   2118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2119\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misreg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2120\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakefile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2121\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2122\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\dellatsni\\adocana\\lib\\tarfile.py\u001b[0m in \u001b[0;36mmakefile\u001b[1;34m(self, tarinfo, targetpath)\u001b[0m\n\u001b[0;32m   2167\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2168\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2169\u001b[1;33m                 \u001b[0mcopyfileobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mReadError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2171\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmakeunknown\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\dellatsni\\adocana\\lib\\tarfile.py\u001b[0m in \u001b[0;36mcopyfileobj\u001b[1;34m(src, dst, length, exception, bufsize)\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mremainder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdivmod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m         \u001b[0mbuf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbufsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"unexpected end of data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\dellatsni\\adocana\\lib\\gzip.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    274\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0merrno\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEBADF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"read() on write-only GzipFile object\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\dellatsni\\adocana\\lib\\_compression.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mview\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"B\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mbyte_view\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m             \u001b[0mbyte_view\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\dellatsni\\adocana\\lib\\gzip.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    480\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34mb\"\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m                 raise EOFError(\"Compressed file ended before the \"\n\u001b[0m\u001b[0;32m    483\u001b[0m                                \"end-of-stream marker was reached\")\n\u001b[0;32m    484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mEOFError\u001b[0m: Compressed file ended before the end-of-stream marker was reached"
     ]
    }
   ],
   "source": [
    "### Loading the training and test sets\n",
    "# Converting the images for PILImage to tensor, so they can be accepted as the input to the network\n",
    "transform = transforms.compose ([transforms.Resize(size, interpolation=2),transforms.ToTensor()])\n",
    "\n",
    "trainset = torchvision.datasets.STL10(root='./data', split='unlabeled', transform=transform, target_transform=None, download=True)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = torchvision.datasets.STL10(root='./data', split='test', transform=transform, target_transform=None, download=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Computes gradient penalty loss for A-WGAN\n",
    "# LAMBDA = 10\n",
    "def computeGradientPenalty(D, realSample, fakeSample):\n",
    "    alpha = Tensor(np.random.random((realSample.size(0), 1, 1, 1)))\n",
    "    interpolate = alpha * realSample + ((1 - alpha) * fakeSample)\n",
    "    interpolate = autograd.Variable(interpolate, requries_grad = True)\n",
    "    dInterpolation = D(interpolate)\n",
    "    fakeOutput = Variable(Tensor(realSample.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "    \n",
    "    gradients = autograd.grad(\n",
    "        outputs = dInterpolation,\n",
    "        inputs = interpolate,\n",
    "        grad_outputs = fakeOutput,\n",
    "        create_graph = True,\n",
    "        retain_graph = True,\n",
    "        only_inputs = True)[0]\n",
    "    \n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradientPenalty = ((0,(gradients.norm(2, dim=1)-1)).max()).mean()\n",
    "    return gradientPenalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator loss\n",
    "# alpha = 1000\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "def generatorAdversarialLoss( output_images):\n",
    "    validity = discriminator(output_images)\n",
    "    gen_adv_loss = torch.mean(validity)\n",
    "    \n",
    "    \n",
    "    return gen_adv_loss\n",
    "\n",
    "# def computeGeneratorLoss(inputs, outputs_g1,outputs_g2):\n",
    "def computeGeneratorLoss(inputs, outputs_g1):\n",
    "    # generator 1\n",
    "    gen_adv_loss1 = generatorAdversarialLoss(outputs_g1)\n",
    "    \n",
    "    # generator 2\n",
    "#     gen_adv_loss2 = generatorAdversarialLoss(outputs_g2)\n",
    "    \n",
    "    i_loss = criterion(inputs, outputs_g1)\n",
    "    \n",
    "    gen_loss = -gen_adv_loss1 + ALPHA*i_loss\n",
    "    \n",
    "    return gen_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_g1 = optim.Adam(generator1.parameters(), lr = 0.001, betas=(BETA1,BETA2))\n",
    "# optimizer_g2 = optim.Adam(generator2.parameters(), lr = 0.001, betas=(BETA1,BETA2))\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr = 0.001, betas=(BETA1,BETA2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Computes gradient penalty loss for A-WGAN\n",
    "def computeGradientPenalty(D, realSample, fakeSample):\n",
    "    alpha = Tensor(np.random.random((realSample.size(0), 1, 1, 1)))\n",
    "    interpolate = alpha * realSample + ((1 - alpha) * fakeSample)\n",
    "    interpolate = autograd.Variable(interpolate, requries_grad = True)\n",
    "    dInterpolation = D(interpolate)\n",
    "    fakeOutput = Variable(Tensor(realSample.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "    \n",
    "    gradients = autograd.grad(\n",
    "        outputs = dInterpolation,\n",
    "        inputs = interpolate,\n",
    "        grad_outputs = fakeOutput,\n",
    "        create_graph = True,\n",
    "        retain_graph = True,\n",
    "        only_inputs = True)[0]\n",
    "    \n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradientPenalty = ((0,(gradients.norm(2, dim = 1)-1)).max()).mean()\n",
    "    return gradientPenalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrminatorLoss(d1Real, d1Fake, gradPenalty):\n",
    "    return (torch.mean(d1Fake) - torch.mean(d1Real.mean)) + (LAMBDA*gradPenalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(numEpochs):\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        input, dummy = data\n",
    "        target = input\n",
    "        \n",
    "        realImgs = Variable(input.type(Tensor))\n",
    "        noiseImgs = Variable(Tensor(np.random.normal(0,1, (input.shape[0], latentDim))))\n",
    "        \n",
    "        ### TRAIN DISCRIMINATOR\n",
    "        optimizer_d.zero_grad()\n",
    "        fakeImgs = generator1(noiseImgs)\n",
    "        \n",
    "        # Real Images\n",
    "        realValid = discriminator(realImgs)\n",
    "        # Fake Images\n",
    "        fakeValid = discriminator(fakeImgs)\n",
    "        \n",
    "        gradientPenalty = computeGradientPenalty(discriminator, realImgs.data, fakeImgs.data)\n",
    "        dLoss = discriminatorLoss(realValid, fakeValid, gradientPenalty)\n",
    "        dLoss.backward()\n",
    "        optimizer_d.step()\n",
    "        optimizer_g1.zero_grad()\n",
    "        \n",
    "        ### TRAIN GENERATOR\n",
    "        if i % trainNum == 50:\n",
    "            print(\"Hello\" + i)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
